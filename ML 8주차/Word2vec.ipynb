{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "\n",
    "import kerastuner as kt\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family=fm.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()) # for Windows OS user\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from tensorflow import keras\n",
    "from scipy.stats.mstats import gmean\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sys, warnings\n",
    "if not sys.warnoptions: warnings.simplefilter(\"ignore\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BnznjqteM4wT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/L.POINT_train.csv', encoding='UTF-8')\n",
    "test = pd.read_csv('data/L.POINT_test.csv', encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train =  pd.read_csv('data/y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Q2x59OaSM4wT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['PD_BUY_AM']  = train['PD_BUY_AM'].map(lambda x: int(str(x).replace(',','')) )\n",
    "train['PD_BUY_CT']  = train['PD_BUY_CT'].map(lambda x: int(str(x).replace(',','')) )\n",
    "train['TOT_SESS_HR_V']  = train['TOT_SESS_HR_V'].map(lambda x: int(str(x).replace(',','')) )\n",
    "\n",
    "test['PD_BUY_AM']  = test['PD_BUY_AM'].map(lambda x: int(str(x).replace(',','')) )\n",
    "test['PD_BUY_CT']  = test['PD_BUY_CT'].map(lambda x: int(str(x).replace(',','')) )\n",
    "test['TOT_SESS_HR_V']  = test['TOT_SESS_HR_V'].map(lambda x: int(str(x).replace(',','')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['AMOUNT'] = train['PD_BUY_AM'] * train['PD_BUY_CT']\n",
    "test['AMOUNT'] = test['PD_BUY_AM'] * test['PD_BUY_CT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['SESS_DT'], format= '%Y%m%d')\n",
    "test['date'] = pd.to_datetime(test['SESS_DT'], format= '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['PD_C']=train['PD_C'].astype('str')\n",
    "test['PD_C']=test['PD_C'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_data = list(train.groupby('CLNT_ID')['CLAC3_NM'].unique())\n",
    "test_data = list(test.groupby('CLNT_ID')['CLAC3_NM'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(x, n,seed=0):\n",
    "    lst = []\n",
    "    for i in x:\n",
    "        tmp = []\n",
    "        np.random.seed(seed)\n",
    "        for j in range(n):\n",
    "            random.shuffle(i)\n",
    "            tmp += list(i)\n",
    "            lst.append(tmp)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_input = oversample(train_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "w2v = word2vec.Word2Vec(sentences = w2v_input, size = 60, window = 5, min_count = 1, sg = 1,seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 150000/150000 [00:02<00:00, 51828.72it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mean_vector = []\n",
    "for words in tqdm(train_data):\n",
    "    tmp = np.zeros(60)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            tmp += w2v[word]\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    tmp /= cnt\n",
    "    train_mean_vector.append(tmp)\n",
    "train_mean_vector = np.array(train_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 113104/113104 [00:02<00:00, 52532.26it/s]\n"
     ]
    }
   ],
   "source": [
    "test_mean_vector = []\n",
    "for words in tqdm(test_data):\n",
    "    tmp = np.zeros(60)\n",
    "    cnt = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            tmp += w2v[word]\n",
    "            cnt += 1\n",
    "        except:\n",
    "            pass\n",
    "    tmp /= cnt\n",
    "    test_mean_vector.append(tmp)\n",
    "test_mean_vector = np.array(test_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_vector = pd.DataFrame(train_mean_vector)\n",
    "test_mean_vector = pd.DataFrame(test_mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean_vector.isnull().sum().sum(),test_mean_vector.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "## save\n",
    "with open('train_mean_vector_clac3.pickle', 'wb') as f:\n",
    "    pickle.dump(train_mean_vector, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "## save\n",
    "with open('test_mean_vector_clac3.pickle', 'wb') as f:\n",
    "    pickle.dump(test_mean_vector, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('train_mean_vector_clac3.pickle', 'rb') as f:\n",
    "    train_mean_vector_clac3 = pickle.load(f)\n",
    "\n",
    "with open('test_mean_vector_clac3.pickle', 'rb') as f:\n",
    "    test_mean_vector_clac3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "with open('train_mean_vector.pickle', 'rb') as f:\n",
    "    train_mean_vector_pdc = pickle.load(f)\n",
    "\n",
    "with open('test_mean_vector.pickle', 'rb') as f:\n",
    "    test_mean_vector_pdc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train.groupby('CLNT_ID').PD_ADD_NM.first().reset_index(),train_mean_vector_pdc],axis=1).drop('PD_ADD_NM',axis=1)\n",
    "data_te=pd.concat([test.groupby('CLNT_ID').PD_ADD_NM.first().reset_index(),test_mean_vector_pdc],axis=1).drop('PD_ADD_NM',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data,train_mean_vector_clac3],axis=1)\n",
    "data_te=pd.concat([data_te,test_mean_vector_clac3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "EOaPfzjsM4wh"
   },
   "outputs": [],
   "source": [
    "cust_tr = data.CLNT_ID\n",
    "cust_te = data_te.CLNT_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "-EJ8U75AM4wh"
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['CLNT_ID'])\n",
    "X_test = data_te.drop(columns=['CLNT_ID'])\n",
    "\n",
    "y =  pd.read_csv('data/y_train.csv').LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns=np.arange(1,161)\n",
    "X_test.columns=np.arange(1,161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBRFClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 95/95 [1:02:11<00:00, 39.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98, -1.2619433668257964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 사용할 모델 설정 (속도가 빠른 모델 사용 권장)\n",
    "model = LGBMClassifier()\n",
    "\n",
    "# 각 특성과 타깃(class) 사이에 유의한 통계적 관계가 있는지 계산하여 특성을 선택하는 방법 \n",
    "cv_scores = []\n",
    "\n",
    "sscv = ShuffleSplit(n_splits = 5, random_state = 0)\n",
    "\n",
    "for p in tqdm(range(5,100,1)):\n",
    "    X_new = SelectPercentile(percentile=p).fit_transform(X, y)    \n",
    "    cv_score = cross_val_score(model, X_new, y, scoring='neg_log_loss', cv=sscv).mean()\n",
    "    cv_scores.append((p,cv_score))\n",
    "\n",
    "# Print the best percentile\n",
    "best_score = cv_scores[np.argmax([score for _, score in cv_scores])]\n",
    "print(best_score)\n",
    "\n",
    "# Plot the performance change with p\n",
    "plt.plot([k for k, _ in cv_scores], [score for _, score in cv_scores])\n",
    "plt.xlabel('Percent of features')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = SelectPercentile(percentile=best_score[0]).fit(X, y)\n",
    "train_selected = fs.transform(X)\n",
    "test_selected = fs.transform(X_test)\n",
    "X_train_select=pd.DataFrame(train_selected,columns=X.columns[fs.get_support()].tolist())\n",
    "X_test_select=pd.DataFrame(test_selected,columns=X.columns[fs.get_support()].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################코드 돌아가면 소리 나는거################### \n",
    "import winsound as sd\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms = =1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = X_train_select\n",
    "target=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105000, 156), (45000, 156))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(ftr, target, test_size=0.3, random_state=0)\n",
    "train_x.shape, valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_params = {\n",
    "    'max_depth':(8, 16),\n",
    "    'num_leaves':(24, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_log_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample, \n",
    "                colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    \n",
    "    params = {\n",
    "        \"n_estimators\":2000, \n",
    "        \"learning_rate\":0.02,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': max(reg_lambda,0),\n",
    "        'reg_alpha': max(reg_alpha, 0)\n",
    "    }\n",
    "    \n",
    "    lgb_model = LGBMClassifier(**params)\n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric='logloss', verbose=100, \n",
    "                early_stopping_rounds=100)\n",
    "    valid_pred = lgb_model.predict_proba(valid_x)\n",
    "    log_score = log_loss(valid_y, valid_pred)\n",
    "    \n",
    "    return log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.2371\tvalid_1's multi_logloss: 1.27677\n",
      "[200]\ttraining's multi_logloss: 1.19047\tvalid_1's multi_logloss: 1.26106\n",
      "[300]\ttraining's multi_logloss: 1.1555\tvalid_1's multi_logloss: 1.25557\n",
      "[400]\ttraining's multi_logloss: 1.12508\tvalid_1's multi_logloss: 1.25306\n",
      "[500]\ttraining's multi_logloss: 1.09754\tvalid_1's multi_logloss: 1.25177\n",
      "[600]\ttraining's multi_logloss: 1.07218\tvalid_1's multi_logloss: 1.25118\n",
      "Early stopping, best iteration is:\n",
      "[594]\ttraining's multi_logloss: 1.07364\tvalid_1's multi_logloss: 1.25115\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 12.82   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 49.84   \u001b[0m | \u001b[0m 21.88   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24643\tvalid_1's multi_logloss: 1.27775\n",
      "[200]\ttraining's multi_logloss: 1.20534\tvalid_1's multi_logloss: 1.26272\n",
      "[300]\ttraining's multi_logloss: 1.17464\tvalid_1's multi_logloss: 1.25754\n",
      "[400]\ttraining's multi_logloss: 1.14871\tvalid_1's multi_logloss: 1.25508\n",
      "[500]\ttraining's multi_logloss: 1.12572\tvalid_1's multi_logloss: 1.254\n",
      "[600]\ttraining's multi_logloss: 1.10468\tvalid_1's multi_logloss: 1.25364\n",
      "[700]\ttraining's multi_logloss: 1.08479\tvalid_1's multi_logloss: 1.25372\n",
      "Early stopping, best iteration is:\n",
      "[615]\ttraining's multi_logloss: 1.10162\tvalid_1's multi_logloss: 1.25361\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 1.254   \u001b[0m | \u001b[95m 0.6917  \u001b[0m | \u001b[95m 397.9   \u001b[0m | \u001b[95m 12.23   \u001b[0m | \u001b[95m 117.9   \u001b[0m | \u001b[95m 46.35   \u001b[0m | \u001b[95m 26.84   \u001b[0m | \u001b[95m 4.366   \u001b[0m | \u001b[95m 0.2032  \u001b[0m | \u001b[95m 0.9163  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.21774\tvalid_1's multi_logloss: 1.27259\n",
      "[200]\ttraining's multi_logloss: 1.15587\tvalid_1's multi_logloss: 1.25849\n",
      "[300]\ttraining's multi_logloss: 1.10657\tvalid_1's multi_logloss: 1.2547\n",
      "[400]\ttraining's multi_logloss: 1.06419\tvalid_1's multi_logloss: 1.25383\n",
      "[500]\ttraining's multi_logloss: 1.02645\tvalid_1's multi_logloss: 1.25385\n",
      "Early stopping, best iteration is:\n",
      "[420]\ttraining's multi_logloss: 1.05632\tvalid_1's multi_logloss: 1.25374\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 1.254   \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 15.83   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 55.22   \u001b[0m | \u001b[95m 5.923   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24464\tvalid_1's multi_logloss: 1.2787\n",
      "[200]\ttraining's multi_logloss: 1.20307\tvalid_1's multi_logloss: 1.26289\n",
      "[300]\ttraining's multi_logloss: 1.17297\tvalid_1's multi_logloss: 1.2573\n",
      "[400]\ttraining's multi_logloss: 1.14736\tvalid_1's multi_logloss: 1.25494\n",
      "[500]\ttraining's multi_logloss: 1.12415\tvalid_1's multi_logloss: 1.25354\n",
      "[600]\ttraining's multi_logloss: 1.10289\tvalid_1's multi_logloss: 1.25293\n",
      "[700]\ttraining's multi_logloss: 1.08321\tvalid_1's multi_logloss: 1.25273\n",
      "[800]\ttraining's multi_logloss: 1.06492\tvalid_1's multi_logloss: 1.25273\n",
      "Early stopping, best iteration is:\n",
      "[721]\ttraining's multi_logloss: 1.07924\tvalid_1's multi_logloss: 1.25265\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 11.32   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 42.25   \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.2467\tvalid_1's multi_logloss: 1.27935\n",
      "[200]\ttraining's multi_logloss: 1.20727\tvalid_1's multi_logloss: 1.2633\n",
      "[300]\ttraining's multi_logloss: 1.17935\tvalid_1's multi_logloss: 1.25751\n",
      "[400]\ttraining's multi_logloss: 1.15571\tvalid_1's multi_logloss: 1.25468\n",
      "[500]\ttraining's multi_logloss: 1.13485\tvalid_1's multi_logloss: 1.25322\n",
      "[600]\ttraining's multi_logloss: 1.11566\tvalid_1's multi_logloss: 1.25234\n",
      "[700]\ttraining's multi_logloss: 1.09861\tvalid_1's multi_logloss: 1.25185\n",
      "[800]\ttraining's multi_logloss: 1.08253\tvalid_1's multi_logloss: 1.25167\n",
      "[900]\ttraining's multi_logloss: 1.06731\tvalid_1's multi_logloss: 1.25157\n",
      "Early stopping, best iteration is:\n",
      "[879]\ttraining's multi_logloss: 1.07049\tvalid_1's multi_logloss: 1.25154\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 312.3   \u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 41.48   \u001b[0m | \u001b[0m 34.88   \u001b[0m | \u001b[0m 0.6032  \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.21977\tvalid_1's multi_logloss: 1.27241\n",
      "[200]\ttraining's multi_logloss: 1.15926\tvalid_1's multi_logloss: 1.25775\n",
      "[300]\ttraining's multi_logloss: 1.11083\tvalid_1's multi_logloss: 1.25344\n",
      "[400]\ttraining's multi_logloss: 1.06885\tvalid_1's multi_logloss: 1.25181\n",
      "[500]\ttraining's multi_logloss: 1.03125\tvalid_1's multi_logloss: 1.25155\n",
      "[600]\ttraining's multi_logloss: 0.996889\tvalid_1's multi_logloss: 1.25197\n",
      "Early stopping, best iteration is:\n",
      "[500]\ttraining's multi_logloss: 1.03125\tvalid_1's multi_logloss: 1.25155\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.6405  \u001b[0m | \u001b[0m 435.0   \u001b[0m | \u001b[0m 14.0    \u001b[0m | \u001b[0m 169.3   \u001b[0m | \u001b[0m 26.92   \u001b[0m | \u001b[0m 57.69   \u001b[0m | \u001b[0m 5.768   \u001b[0m | \u001b[0m 9.196   \u001b[0m | \u001b[0m 0.613   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24149\tvalid_1's multi_logloss: 1.27878\n",
      "[200]\ttraining's multi_logloss: 1.19924\tvalid_1's multi_logloss: 1.26276\n",
      "[300]\ttraining's multi_logloss: 1.16903\tvalid_1's multi_logloss: 1.25698\n",
      "[400]\ttraining's multi_logloss: 1.14353\tvalid_1's multi_logloss: 1.25421\n",
      "[500]\ttraining's multi_logloss: 1.12092\tvalid_1's multi_logloss: 1.25284\n",
      "[600]\ttraining's multi_logloss: 1.10069\tvalid_1's multi_logloss: 1.252\n",
      "[700]\ttraining's multi_logloss: 1.08245\tvalid_1's multi_logloss: 1.25161\n",
      "[800]\ttraining's multi_logloss: 1.06584\tvalid_1's multi_logloss: 1.25153\n",
      "Early stopping, best iteration is:\n",
      "[780]\ttraining's multi_logloss: 1.0693\tvalid_1's multi_logloss: 1.25145\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.6323  \u001b[0m | \u001b[0m 429.3   \u001b[0m | \u001b[0m 12.36   \u001b[0m | \u001b[0m 45.04   \u001b[0m | \u001b[0m 4.494   \u001b[0m | \u001b[0m 57.66   \u001b[0m | \u001b[0m 42.36   \u001b[0m | \u001b[0m 0.592   \u001b[0m | \u001b[0m 0.8029  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.25338\tvalid_1's multi_logloss: 1.28097\n",
      "[200]\ttraining's multi_logloss: 1.21727\tvalid_1's multi_logloss: 1.26463\n",
      "[300]\ttraining's multi_logloss: 1.19259\tvalid_1's multi_logloss: 1.25858\n",
      "[400]\ttraining's multi_logloss: 1.17213\tvalid_1's multi_logloss: 1.25559\n",
      "[500]\ttraining's multi_logloss: 1.15399\tvalid_1's multi_logloss: 1.2537\n",
      "[600]\ttraining's multi_logloss: 1.13752\tvalid_1's multi_logloss: 1.25268\n",
      "[700]\ttraining's multi_logloss: 1.12263\tvalid_1's multi_logloss: 1.25217\n",
      "[800]\ttraining's multi_logloss: 1.10896\tvalid_1's multi_logloss: 1.25184\n",
      "[900]\ttraining's multi_logloss: 1.09601\tvalid_1's multi_logloss: 1.25171\n",
      "[1000]\ttraining's multi_logloss: 1.08368\tvalid_1's multi_logloss: 1.2516\n",
      "[1100]\ttraining's multi_logloss: 1.07226\tvalid_1's multi_logloss: 1.2516\n",
      "Early stopping, best iteration is:\n",
      "[1023]\ttraining's multi_logloss: 1.08099\tvalid_1's multi_logloss: 1.25156\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.7427  \u001b[0m | \u001b[0m 319.5   \u001b[0m | \u001b[0m 11.14   \u001b[0m | \u001b[0m 111.8   \u001b[0m | \u001b[0m 35.35   \u001b[0m | \u001b[0m 35.0    \u001b[0m | \u001b[0m 36.71   \u001b[0m | \u001b[0m 3.602   \u001b[0m | \u001b[0m 0.9431  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24813\tvalid_1's multi_logloss: 1.27956\n",
      "[200]\ttraining's multi_logloss: 1.20875\tvalid_1's multi_logloss: 1.26325\n",
      "[300]\ttraining's multi_logloss: 1.18071\tvalid_1's multi_logloss: 1.2573\n",
      "[400]\ttraining's multi_logloss: 1.157\tvalid_1's multi_logloss: 1.25439\n",
      "[500]\ttraining's multi_logloss: 1.13579\tvalid_1's multi_logloss: 1.25268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttraining's multi_logloss: 1.11609\tvalid_1's multi_logloss: 1.25177\n",
      "[700]\ttraining's multi_logloss: 1.0979\tvalid_1's multi_logloss: 1.25122\n",
      "[800]\ttraining's multi_logloss: 1.08084\tvalid_1's multi_logloss: 1.25088\n",
      "[900]\ttraining's multi_logloss: 1.06502\tvalid_1's multi_logloss: 1.25087\n",
      "Early stopping, best iteration is:\n",
      "[855]\ttraining's multi_logloss: 1.07201\tvalid_1's multi_logloss: 1.25084\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.6409  \u001b[0m | \u001b[0m 182.8   \u001b[0m | \u001b[0m 11.53   \u001b[0m | \u001b[0m 43.94   \u001b[0m | \u001b[0m 33.35   \u001b[0m | \u001b[0m 40.72   \u001b[0m | \u001b[0m 29.16   \u001b[0m | \u001b[0m 6.572   \u001b[0m | \u001b[0m 0.7809  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24975\tvalid_1's multi_logloss: 1.28123\n",
      "[200]\ttraining's multi_logloss: 1.21168\tvalid_1's multi_logloss: 1.26498\n",
      "[300]\ttraining's multi_logloss: 1.1856\tvalid_1's multi_logloss: 1.25917\n",
      "[400]\ttraining's multi_logloss: 1.16409\tvalid_1's multi_logloss: 1.25626\n",
      "[500]\ttraining's multi_logloss: 1.14521\tvalid_1's multi_logloss: 1.25472\n",
      "[600]\ttraining's multi_logloss: 1.12889\tvalid_1's multi_logloss: 1.25381\n",
      "[700]\ttraining's multi_logloss: 1.1139\tvalid_1's multi_logloss: 1.25338\n",
      "[800]\ttraining's multi_logloss: 1.10002\tvalid_1's multi_logloss: 1.25307\n",
      "[900]\ttraining's multi_logloss: 1.08737\tvalid_1's multi_logloss: 1.25297\n",
      "[1000]\ttraining's multi_logloss: 1.07833\tvalid_1's multi_logloss: 1.25278\n",
      "[1100]\ttraining's multi_logloss: 1.06962\tvalid_1's multi_logloss: 1.25275\n",
      "Early stopping, best iteration is:\n",
      "[1058]\ttraining's multi_logloss: 1.0732\tvalid_1's multi_logloss: 1.25271\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.9628  \u001b[0m | \u001b[0m 392.6   \u001b[0m | \u001b[0m 12.6    \u001b[0m | \u001b[0m 137.6   \u001b[0m | \u001b[0m 6.163   \u001b[0m | \u001b[0m 39.69   \u001b[0m | \u001b[0m 44.62   \u001b[0m | \u001b[0m 7.968   \u001b[0m | \u001b[0m 0.7126  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.22734\tvalid_1's multi_logloss: 1.27378\n",
      "[200]\ttraining's multi_logloss: 1.17318\tvalid_1's multi_logloss: 1.25907\n",
      "[300]\ttraining's multi_logloss: 1.13055\tvalid_1's multi_logloss: 1.2545\n",
      "[400]\ttraining's multi_logloss: 1.09362\tvalid_1's multi_logloss: 1.25274\n",
      "[500]\ttraining's multi_logloss: 1.06063\tvalid_1's multi_logloss: 1.2521\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's multi_logloss: 1.06094\tvalid_1's multi_logloss: 1.25209\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.8032  \u001b[0m | \u001b[0m 289.9   \u001b[0m | \u001b[0m 14.48   \u001b[0m | \u001b[0m 135.2   \u001b[0m | \u001b[0m 29.54   \u001b[0m | \u001b[0m 49.69   \u001b[0m | \u001b[0m 9.132   \u001b[0m | \u001b[0m 6.842   \u001b[0m | \u001b[0m 0.9468  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.23119\tvalid_1's multi_logloss: 1.27614\n",
      "[200]\ttraining's multi_logloss: 1.18106\tvalid_1's multi_logloss: 1.26091\n",
      "[300]\ttraining's multi_logloss: 1.14281\tvalid_1's multi_logloss: 1.25599\n",
      "[400]\ttraining's multi_logloss: 1.10948\tvalid_1's multi_logloss: 1.25389\n",
      "[500]\ttraining's multi_logloss: 1.07913\tvalid_1's multi_logloss: 1.2531\n",
      "[600]\ttraining's multi_logloss: 1.0513\tvalid_1's multi_logloss: 1.25288\n",
      "[700]\ttraining's multi_logloss: 1.02534\tvalid_1's multi_logloss: 1.25305\n",
      "Early stopping, best iteration is:\n",
      "[611]\ttraining's multi_logloss: 1.04835\tvalid_1's multi_logloss: 1.25283\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.9302  \u001b[0m | \u001b[0m 239.3   \u001b[0m | \u001b[0m 10.73   \u001b[0m | \u001b[0m 141.8   \u001b[0m | \u001b[0m 4.039   \u001b[0m | \u001b[0m 56.17   \u001b[0m | \u001b[0m 23.41   \u001b[0m | \u001b[0m 8.839   \u001b[0m | \u001b[0m 0.9091  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.22647\tvalid_1's multi_logloss: 1.27456\n",
      "[200]\ttraining's multi_logloss: 1.17275\tvalid_1's multi_logloss: 1.25933\n",
      "[300]\ttraining's multi_logloss: 1.13102\tvalid_1's multi_logloss: 1.2546\n",
      "[400]\ttraining's multi_logloss: 1.09485\tvalid_1's multi_logloss: 1.25273\n",
      "[500]\ttraining's multi_logloss: 1.06196\tvalid_1's multi_logloss: 1.25207\n",
      "[600]\ttraining's multi_logloss: 1.03189\tvalid_1's multi_logloss: 1.25208\n",
      "Early stopping, best iteration is:\n",
      "[547]\ttraining's multi_logloss: 1.04759\tvalid_1's multi_logloss: 1.25197\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.8227  \u001b[0m | \u001b[0m 418.8   \u001b[0m | \u001b[0m 9.865   \u001b[0m | \u001b[0m 51.9    \u001b[0m | \u001b[0m 10.05   \u001b[0m | \u001b[0m 55.87   \u001b[0m | \u001b[0m 15.55   \u001b[0m | \u001b[0m 8.403   \u001b[0m | \u001b[0m 0.9562  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.22763\tvalid_1's multi_logloss: 1.2744\n",
      "[200]\ttraining's multi_logloss: 1.17375\tvalid_1's multi_logloss: 1.26023\n",
      "[300]\ttraining's multi_logloss: 1.13148\tvalid_1's multi_logloss: 1.25597\n",
      "[400]\ttraining's multi_logloss: 1.09534\tvalid_1's multi_logloss: 1.25447\n",
      "[500]\ttraining's multi_logloss: 1.06302\tvalid_1's multi_logloss: 1.25398\n",
      "[600]\ttraining's multi_logloss: 1.03342\tvalid_1's multi_logloss: 1.25425\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's multi_logloss: 1.06\tvalid_1's multi_logloss: 1.25396\n",
      "| \u001b[95m 14      \u001b[0m | \u001b[95m 1.254   \u001b[0m | \u001b[95m 0.9781  \u001b[0m | \u001b[95m 232.8   \u001b[0m | \u001b[95m 11.5    \u001b[0m | \u001b[95m 170.4   \u001b[0m | \u001b[95m 30.44   \u001b[0m | \u001b[95m 45.23   \u001b[0m | \u001b[95m 8.401   \u001b[0m | \u001b[95m 0.9375  \u001b[0m | \u001b[95m 0.8085  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.25182\tvalid_1's multi_logloss: 1.28046\n",
      "[200]\ttraining's multi_logloss: 1.21527\tvalid_1's multi_logloss: 1.2646\n",
      "[300]\ttraining's multi_logloss: 1.18966\tvalid_1's multi_logloss: 1.25881\n",
      "[400]\ttraining's multi_logloss: 1.16813\tvalid_1's multi_logloss: 1.25593\n",
      "[500]\ttraining's multi_logloss: 1.14922\tvalid_1's multi_logloss: 1.25434\n",
      "[600]\ttraining's multi_logloss: 1.13212\tvalid_1's multi_logloss: 1.25347\n",
      "[700]\ttraining's multi_logloss: 1.11639\tvalid_1's multi_logloss: 1.25288\n",
      "[800]\ttraining's multi_logloss: 1.10169\tvalid_1's multi_logloss: 1.2528\n",
      "[900]\ttraining's multi_logloss: 1.0885\tvalid_1's multi_logloss: 1.25262\n",
      "[1000]\ttraining's multi_logloss: 1.07598\tvalid_1's multi_logloss: 1.2526\n",
      "[1100]\ttraining's multi_logloss: 1.06398\tvalid_1's multi_logloss: 1.25264\n",
      "Early stopping, best iteration is:\n",
      "[1014]\ttraining's multi_logloss: 1.07428\tvalid_1's multi_logloss: 1.25255\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.9303  \u001b[0m | \u001b[0m 325.1   \u001b[0m | \u001b[0m 15.93   \u001b[0m | \u001b[0m 120.2   \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 29.0    \u001b[0m | \u001b[0m 25.81   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 0.5704  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.23081\tvalid_1's multi_logloss: 1.27418\n",
      "[200]\ttraining's multi_logloss: 1.17939\tvalid_1's multi_logloss: 1.25911\n",
      "[300]\ttraining's multi_logloss: 1.13936\tvalid_1's multi_logloss: 1.25423\n",
      "[400]\ttraining's multi_logloss: 1.10461\tvalid_1's multi_logloss: 1.25206\n",
      "[500]\ttraining's multi_logloss: 1.07349\tvalid_1's multi_logloss: 1.25124\n",
      "[600]\ttraining's multi_logloss: 1.04466\tvalid_1's multi_logloss: 1.25122\n",
      "Early stopping, best iteration is:\n",
      "[540]\ttraining's multi_logloss: 1.06175\tvalid_1's multi_logloss: 1.25107\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.7405  \u001b[0m | \u001b[0m 120.1   \u001b[0m | \u001b[0m 12.94   \u001b[0m | \u001b[0m 53.76   \u001b[0m | \u001b[0m 42.68   \u001b[0m | \u001b[0m 47.66   \u001b[0m | \u001b[0m 10.66   \u001b[0m | \u001b[0m 1.986   \u001b[0m | \u001b[0m 0.8184  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24187\tvalid_1's multi_logloss: 1.27816\n",
      "[200]\ttraining's multi_logloss: 1.1973\tvalid_1's multi_logloss: 1.26154\n",
      "[300]\ttraining's multi_logloss: 1.16472\tvalid_1's multi_logloss: 1.25564\n",
      "[400]\ttraining's multi_logloss: 1.13661\tvalid_1's multi_logloss: 1.2529\n",
      "[500]\ttraining's multi_logloss: 1.11111\tvalid_1's multi_logloss: 1.25161\n",
      "[600]\ttraining's multi_logloss: 1.08739\tvalid_1's multi_logloss: 1.25074\n",
      "[700]\ttraining's multi_logloss: 1.06504\tvalid_1's multi_logloss: 1.2504\n",
      "[800]\ttraining's multi_logloss: 1.04406\tvalid_1's multi_logloss: 1.2504\n",
      "[900]\ttraining's multi_logloss: 1.02456\tvalid_1's multi_logloss: 1.25047\n",
      "Early stopping, best iteration is:\n",
      "[826]\ttraining's multi_logloss: 1.03886\tvalid_1's multi_logloss: 1.25032\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 1.25    \u001b[0m | \u001b[0m 0.5286  \u001b[0m | \u001b[0m 456.4   \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 96.72   \u001b[0m | \u001b[0m 41.56   \u001b[0m | \u001b[0m 61.51   \u001b[0m | \u001b[0m 29.92   \u001b[0m | \u001b[0m 3.57    \u001b[0m | \u001b[0m 0.8466  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24287\tvalid_1's multi_logloss: 1.27799\n",
      "[200]\ttraining's multi_logloss: 1.2006\tvalid_1's multi_logloss: 1.26219\n",
      "[300]\ttraining's multi_logloss: 1.16979\tvalid_1's multi_logloss: 1.25666\n",
      "[400]\ttraining's multi_logloss: 1.14339\tvalid_1's multi_logloss: 1.25418\n",
      "[500]\ttraining's multi_logloss: 1.11959\tvalid_1's multi_logloss: 1.25286\n",
      "[600]\ttraining's multi_logloss: 1.0979\tvalid_1's multi_logloss: 1.25228\n",
      "[700]\ttraining's multi_logloss: 1.07779\tvalid_1's multi_logloss: 1.252\n",
      "[800]\ttraining's multi_logloss: 1.05885\tvalid_1's multi_logloss: 1.25199\n",
      "Early stopping, best iteration is:\n",
      "[788]\ttraining's multi_logloss: 1.06104\tvalid_1's multi_logloss: 1.25197\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.8263  \u001b[0m | \u001b[0m 179.0   \u001b[0m | \u001b[0m 12.19   \u001b[0m | \u001b[0m 25.42   \u001b[0m | \u001b[0m 22.47   \u001b[0m | \u001b[0m 41.44   \u001b[0m | \u001b[0m 25.05   \u001b[0m | \u001b[0m 2.005   \u001b[0m | \u001b[0m 0.6375  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24952\tvalid_1's multi_logloss: 1.28062\n",
      "[200]\ttraining's multi_logloss: 1.21103\tvalid_1's multi_logloss: 1.26422\n",
      "[300]\ttraining's multi_logloss: 1.18426\tvalid_1's multi_logloss: 1.25838\n",
      "[400]\ttraining's multi_logloss: 1.16191\tvalid_1's multi_logloss: 1.25561\n",
      "[500]\ttraining's multi_logloss: 1.14209\tvalid_1's multi_logloss: 1.25399\n",
      "[600]\ttraining's multi_logloss: 1.12436\tvalid_1's multi_logloss: 1.25297\n",
      "[700]\ttraining's multi_logloss: 1.10815\tvalid_1's multi_logloss: 1.25256\n",
      "[800]\ttraining's multi_logloss: 1.09334\tvalid_1's multi_logloss: 1.2523\n",
      "[900]\ttraining's multi_logloss: 1.07997\tvalid_1's multi_logloss: 1.25222\n",
      "[1000]\ttraining's multi_logloss: 1.06778\tvalid_1's multi_logloss: 1.25222\n",
      "Early stopping, best iteration is:\n",
      "[962]\ttraining's multi_logloss: 1.07236\tvalid_1's multi_logloss: 1.2522\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.9644  \u001b[0m | \u001b[0m 330.1   \u001b[0m | \u001b[0m 11.74   \u001b[0m | \u001b[0m 22.2    \u001b[0m | \u001b[0m 30.45   \u001b[0m | \u001b[0m 42.41   \u001b[0m | \u001b[0m 41.12   \u001b[0m | \u001b[0m 7.102   \u001b[0m | \u001b[0m 0.755   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.2449\tvalid_1's multi_logloss: 1.27884\n",
      "[200]\ttraining's multi_logloss: 1.20477\tvalid_1's multi_logloss: 1.26292\n",
      "[300]\ttraining's multi_logloss: 1.17646\tvalid_1's multi_logloss: 1.25738\n",
      "[400]\ttraining's multi_logloss: 1.15237\tvalid_1's multi_logloss: 1.25462\n",
      "[500]\ttraining's multi_logloss: 1.13084\tvalid_1's multi_logloss: 1.25304\n",
      "[600]\ttraining's multi_logloss: 1.11091\tvalid_1's multi_logloss: 1.25217\n",
      "[700]\ttraining's multi_logloss: 1.09299\tvalid_1's multi_logloss: 1.25173\n",
      "[800]\ttraining's multi_logloss: 1.07605\tvalid_1's multi_logloss: 1.25151\n",
      "[900]\ttraining's multi_logloss: 1.06012\tvalid_1's multi_logloss: 1.25159\n",
      "Early stopping, best iteration is:\n",
      "[826]\ttraining's multi_logloss: 1.07181\tvalid_1's multi_logloss: 1.25147\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.6988  \u001b[0m | \u001b[0m 466.8   \u001b[0m | \u001b[0m 8.179   \u001b[0m | \u001b[0m 141.3   \u001b[0m | \u001b[0m 6.811   \u001b[0m | \u001b[0m 46.3    \u001b[0m | \u001b[0m 34.41   \u001b[0m | \u001b[0m 0.2103  \u001b[0m | \u001b[0m 0.8806  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.25586\tvalid_1's multi_logloss: 1.28202\n",
      "[200]\ttraining's multi_logloss: 1.22041\tvalid_1's multi_logloss: 1.26529\n",
      "[300]\ttraining's multi_logloss: 1.1967\tvalid_1's multi_logloss: 1.25892\n",
      "[400]\ttraining's multi_logloss: 1.17722\tvalid_1's multi_logloss: 1.25571\n",
      "[500]\ttraining's multi_logloss: 1.16\tvalid_1's multi_logloss: 1.25376\n",
      "[600]\ttraining's multi_logloss: 1.14439\tvalid_1's multi_logloss: 1.25255\n",
      "[700]\ttraining's multi_logloss: 1.1302\tvalid_1's multi_logloss: 1.2519\n",
      "[800]\ttraining's multi_logloss: 1.11713\tvalid_1's multi_logloss: 1.25155\n",
      "[900]\ttraining's multi_logloss: 1.10501\tvalid_1's multi_logloss: 1.25129\n",
      "[1000]\ttraining's multi_logloss: 1.09414\tvalid_1's multi_logloss: 1.25122\n",
      "[1100]\ttraining's multi_logloss: 1.08424\tvalid_1's multi_logloss: 1.25111\n",
      "[1200]\ttraining's multi_logloss: 1.07463\tvalid_1's multi_logloss: 1.25107\n",
      "[1300]\ttraining's multi_logloss: 1.06624\tvalid_1's multi_logloss: 1.25103\n",
      "Early stopping, best iteration is:\n",
      "[1222]\ttraining's multi_logloss: 1.0726\tvalid_1's multi_logloss: 1.25101\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.6587  \u001b[0m | \u001b[0m 250.5   \u001b[0m | \u001b[0m 11.19   \u001b[0m | \u001b[0m 100.8   \u001b[0m | \u001b[0m 48.75   \u001b[0m | \u001b[0m 36.58   \u001b[0m | \u001b[0m 41.15   \u001b[0m | \u001b[0m 9.618   \u001b[0m | \u001b[0m 0.6229  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24897\tvalid_1's multi_logloss: 1.28036\n",
      "[200]\ttraining's multi_logloss: 1.21055\tvalid_1's multi_logloss: 1.26426\n",
      "[300]\ttraining's multi_logloss: 1.18346\tvalid_1's multi_logloss: 1.25856\n",
      "[400]\ttraining's multi_logloss: 1.16067\tvalid_1's multi_logloss: 1.2559\n",
      "[500]\ttraining's multi_logloss: 1.14076\tvalid_1's multi_logloss: 1.25438\n",
      "[600]\ttraining's multi_logloss: 1.12274\tvalid_1's multi_logloss: 1.25342\n",
      "[700]\ttraining's multi_logloss: 1.10693\tvalid_1's multi_logloss: 1.25297\n",
      "[800]\ttraining's multi_logloss: 1.09214\tvalid_1's multi_logloss: 1.25272\n",
      "[900]\ttraining's multi_logloss: 1.0779\tvalid_1's multi_logloss: 1.25261\n",
      "[1000]\ttraining's multi_logloss: 1.06446\tvalid_1's multi_logloss: 1.25272\n",
      "Early stopping, best iteration is:\n",
      "[916]\ttraining's multi_logloss: 1.07568\tvalid_1's multi_logloss: 1.25259\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.9983  \u001b[0m | \u001b[0m 254.0   \u001b[0m | \u001b[0m 15.72   \u001b[0m | \u001b[0m 172.3   \u001b[0m | \u001b[0m 4.75    \u001b[0m | \u001b[0m 36.0    \u001b[0m | \u001b[0m 34.22   \u001b[0m | \u001b[0m 8.13    \u001b[0m | \u001b[0m 0.8197  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.25418\tvalid_1's multi_logloss: 1.28218\n",
      "[200]\ttraining's multi_logloss: 1.2181\tvalid_1's multi_logloss: 1.26568\n",
      "[300]\ttraining's multi_logloss: 1.19383\tvalid_1's multi_logloss: 1.25946\n",
      "[400]\ttraining's multi_logloss: 1.17396\tvalid_1's multi_logloss: 1.2564\n",
      "[500]\ttraining's multi_logloss: 1.15672\tvalid_1's multi_logloss: 1.25479\n",
      "[600]\ttraining's multi_logloss: 1.14172\tvalid_1's multi_logloss: 1.25391\n",
      "[700]\ttraining's multi_logloss: 1.12817\tvalid_1's multi_logloss: 1.25321\n",
      "[800]\ttraining's multi_logloss: 1.11617\tvalid_1's multi_logloss: 1.25295\n",
      "[900]\ttraining's multi_logloss: 1.10559\tvalid_1's multi_logloss: 1.25275\n",
      "[1000]\ttraining's multi_logloss: 1.09668\tvalid_1's multi_logloss: 1.2526\n",
      "[1100]\ttraining's multi_logloss: 1.08848\tvalid_1's multi_logloss: 1.25253\n",
      "[1200]\ttraining's multi_logloss: 1.0805\tvalid_1's multi_logloss: 1.25248\n",
      "[1300]\ttraining's multi_logloss: 1.07352\tvalid_1's multi_logloss: 1.25251\n",
      "Early stopping, best iteration is:\n",
      "[1201]\ttraining's multi_logloss: 1.08043\tvalid_1's multi_logloss: 1.25247\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.9707  \u001b[0m | \u001b[0m 151.7   \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 46.18   \u001b[0m | \u001b[0m 37.89   \u001b[0m | \u001b[0m 38.31   \u001b[0m | \u001b[0m 47.9    \u001b[0m | \u001b[0m 5.181   \u001b[0m | \u001b[0m 0.5227  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.23356\tvalid_1's multi_logloss: 1.27643\n",
      "[200]\ttraining's multi_logloss: 1.18453\tvalid_1's multi_logloss: 1.26066\n",
      "[300]\ttraining's multi_logloss: 1.14743\tvalid_1's multi_logloss: 1.25561\n",
      "[400]\ttraining's multi_logloss: 1.11514\tvalid_1's multi_logloss: 1.25329\n",
      "[500]\ttraining's multi_logloss: 1.0857\tvalid_1's multi_logloss: 1.25221\n",
      "[600]\ttraining's multi_logloss: 1.05842\tvalid_1's multi_logloss: 1.25176\n",
      "[700]\ttraining's multi_logloss: 1.03319\tvalid_1's multi_logloss: 1.2517\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's multi_logloss: 1.04336\tvalid_1's multi_logloss: 1.25167\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.8324  \u001b[0m | \u001b[0m 52.63   \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 100.8   \u001b[0m | \u001b[0m 22.84   \u001b[0m | \u001b[0m 59.28   \u001b[0m | \u001b[0m 25.3    \u001b[0m | \u001b[0m 7.74    \u001b[0m | \u001b[0m 0.9656  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24107\tvalid_1's multi_logloss: 1.27851\n",
      "[200]\ttraining's multi_logloss: 1.19688\tvalid_1's multi_logloss: 1.26229\n",
      "[300]\ttraining's multi_logloss: 1.16481\tvalid_1's multi_logloss: 1.25674\n",
      "[400]\ttraining's multi_logloss: 1.13747\tvalid_1's multi_logloss: 1.25417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 1.11282\tvalid_1's multi_logloss: 1.25272\n",
      "[600]\ttraining's multi_logloss: 1.09007\tvalid_1's multi_logloss: 1.25179\n",
      "[700]\ttraining's multi_logloss: 1.06905\tvalid_1's multi_logloss: 1.25146\n",
      "[800]\ttraining's multi_logloss: 1.04979\tvalid_1's multi_logloss: 1.25143\n",
      "Early stopping, best iteration is:\n",
      "[723]\ttraining's multi_logloss: 1.06451\tvalid_1's multi_logloss: 1.25139\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.7945  \u001b[0m | \u001b[0m 227.7   \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 10.97   \u001b[0m | \u001b[0m 29.73   \u001b[0m | \u001b[0m 58.59   \u001b[0m | \u001b[0m 36.54   \u001b[0m | \u001b[0m 5.997   \u001b[0m | \u001b[0m 0.619   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.22961\tvalid_1's multi_logloss: 1.27438\n",
      "[200]\ttraining's multi_logloss: 1.17739\tvalid_1's multi_logloss: 1.25878\n",
      "[300]\ttraining's multi_logloss: 1.13674\tvalid_1's multi_logloss: 1.25388\n",
      "[400]\ttraining's multi_logloss: 1.10108\tvalid_1's multi_logloss: 1.25166\n",
      "[500]\ttraining's multi_logloss: 1.06872\tvalid_1's multi_logloss: 1.25067\n",
      "[600]\ttraining's multi_logloss: 1.03889\tvalid_1's multi_logloss: 1.25031\n",
      "[700]\ttraining's multi_logloss: 1.01119\tvalid_1's multi_logloss: 1.2505\n",
      "Early stopping, best iteration is:\n",
      "[613]\ttraining's multi_logloss: 1.03521\tvalid_1's multi_logloss: 1.25027\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 1.25    \u001b[0m | \u001b[0m 0.5221  \u001b[0m | \u001b[0m 85.95   \u001b[0m | \u001b[0m 13.64   \u001b[0m | \u001b[0m 31.7    \u001b[0m | \u001b[0m 25.54   \u001b[0m | \u001b[0m 55.78   \u001b[0m | \u001b[0m 13.9    \u001b[0m | \u001b[0m 1.522   \u001b[0m | \u001b[0m 0.9647  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.25274\tvalid_1's multi_logloss: 1.28177\n",
      "[200]\ttraining's multi_logloss: 1.21582\tvalid_1's multi_logloss: 1.26533\n",
      "[300]\ttraining's multi_logloss: 1.19097\tvalid_1's multi_logloss: 1.25922\n",
      "[400]\ttraining's multi_logloss: 1.17068\tvalid_1's multi_logloss: 1.25611\n",
      "[500]\ttraining's multi_logloss: 1.15287\tvalid_1's multi_logloss: 1.25438\n",
      "[600]\ttraining's multi_logloss: 1.13719\tvalid_1's multi_logloss: 1.25333\n",
      "[700]\ttraining's multi_logloss: 1.12301\tvalid_1's multi_logloss: 1.25276\n",
      "[800]\ttraining's multi_logloss: 1.11078\tvalid_1's multi_logloss: 1.25233\n",
      "[900]\ttraining's multi_logloss: 1.10019\tvalid_1's multi_logloss: 1.25207\n",
      "[1000]\ttraining's multi_logloss: 1.09077\tvalid_1's multi_logloss: 1.25184\n",
      "[1100]\ttraining's multi_logloss: 1.08127\tvalid_1's multi_logloss: 1.25178\n",
      "[1200]\ttraining's multi_logloss: 1.07277\tvalid_1's multi_logloss: 1.2518\n",
      "Early stopping, best iteration is:\n",
      "[1114]\ttraining's multi_logloss: 1.07997\tvalid_1's multi_logloss: 1.25177\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 0.8719  \u001b[0m | \u001b[0m 449.5   \u001b[0m | \u001b[0m 9.927   \u001b[0m | \u001b[0m 64.2    \u001b[0m | \u001b[0m 32.31   \u001b[0m | \u001b[0m 42.56   \u001b[0m | \u001b[0m 49.45   \u001b[0m | \u001b[0m 7.164   \u001b[0m | \u001b[0m 0.8816  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.24096\tvalid_1's multi_logloss: 1.27797\n",
      "[200]\ttraining's multi_logloss: 1.19728\tvalid_1's multi_logloss: 1.26226\n",
      "[300]\ttraining's multi_logloss: 1.16533\tvalid_1's multi_logloss: 1.25708\n",
      "[400]\ttraining's multi_logloss: 1.13795\tvalid_1's multi_logloss: 1.25468\n",
      "[500]\ttraining's multi_logloss: 1.11307\tvalid_1's multi_logloss: 1.25327\n",
      "[600]\ttraining's multi_logloss: 1.09007\tvalid_1's multi_logloss: 1.25282\n",
      "[700]\ttraining's multi_logloss: 1.06883\tvalid_1's multi_logloss: 1.25263\n",
      "[800]\ttraining's multi_logloss: 1.04901\tvalid_1's multi_logloss: 1.25279\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttraining's multi_logloss: 1.0674\tvalid_1's multi_logloss: 1.25261\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.959   \u001b[0m | \u001b[0m 242.5   \u001b[0m | \u001b[0m 9.055   \u001b[0m | \u001b[0m 161.5   \u001b[0m | \u001b[0m 26.26   \u001b[0m | \u001b[0m 47.09   \u001b[0m | \u001b[0m 28.48   \u001b[0m | \u001b[0m 1.268   \u001b[0m | \u001b[0m 0.7036  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.22651\tvalid_1's multi_logloss: 1.27325\n",
      "[200]\ttraining's multi_logloss: 1.17124\tvalid_1's multi_logloss: 1.25807\n",
      "[300]\ttraining's multi_logloss: 1.12765\tvalid_1's multi_logloss: 1.25338\n",
      "[400]\ttraining's multi_logloss: 1.08956\tvalid_1's multi_logloss: 1.25151\n",
      "[500]\ttraining's multi_logloss: 1.05513\tvalid_1's multi_logloss: 1.25081\n",
      "[600]\ttraining's multi_logloss: 1.02351\tvalid_1's multi_logloss: 1.25079\n",
      "Early stopping, best iteration is:\n",
      "[571]\ttraining's multi_logloss: 1.03244\tvalid_1's multi_logloss: 1.2507\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 1.251   \u001b[0m | \u001b[0m 0.5288  \u001b[0m | \u001b[0m 298.4   \u001b[0m | \u001b[0m 14.47   \u001b[0m | \u001b[0m 182.4   \u001b[0m | \u001b[0m 37.65   \u001b[0m | \u001b[0m 54.36   \u001b[0m | \u001b[0m 7.913   \u001b[0m | \u001b[0m 3.01    \u001b[0m | \u001b[0m 0.7732  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 1.23176\tvalid_1's multi_logloss: 1.27458\n",
      "[200]\ttraining's multi_logloss: 1.18097\tvalid_1's multi_logloss: 1.26009\n",
      "[300]\ttraining's multi_logloss: 1.14191\tvalid_1's multi_logloss: 1.2555\n",
      "[400]\ttraining's multi_logloss: 1.10865\tvalid_1's multi_logloss: 1.25365\n",
      "[500]\ttraining's multi_logloss: 1.07896\tvalid_1's multi_logloss: 1.25323\n",
      "Early stopping, best iteration is:\n",
      "[466]\ttraining's multi_logloss: 1.08869\tvalid_1's multi_logloss: 1.25316\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 0.7962  \u001b[0m | \u001b[0m 309.4   \u001b[0m | \u001b[0m 8.872   \u001b[0m | \u001b[0m 194.4   \u001b[0m | \u001b[0m 35.83   \u001b[0m | \u001b[0m 40.28   \u001b[0m | \u001b[0m 5.876   \u001b[0m | \u001b[0m 1.207   \u001b[0m | \u001b[0m 0.6585  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(f=lgb_log_eval, pbounds=bayesian_params, random_state=0)\n",
    "lgbBO.maximize(init_points=5, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 1.251146063157274,\n",
       "  'params': {'colsample_bytree': 0.7744067519636624,\n",
       "   'max_bin': 360.44278952248555,\n",
       "   'max_depth': 12.822107008573152,\n",
       "   'min_child_samples': 113.52780476941041,\n",
       "   'min_child_weight': 21.75908516760633,\n",
       "   'num_leaves': 49.835764522666246,\n",
       "   'reg_alpha': 21.884984691022,\n",
       "   'reg_lambda': 8.917838234820016,\n",
       "   'subsample': 0.9818313802505146}},\n",
       " {'target': 1.2536079279558263,\n",
       "  'params': {'colsample_bytree': 0.6917207594128889,\n",
       "   'max_bin': 397.94526866050563,\n",
       "   'max_depth': 12.231159358023236,\n",
       "   'min_child_samples': 117.92846660784714,\n",
       "   'min_child_weight': 46.35423527634039,\n",
       "   'num_leaves': 26.841442327915477,\n",
       "   'reg_alpha': 4.36559369208002,\n",
       "   'reg_lambda': 0.20316375600581688,\n",
       "   'subsample': 0.916309922773969}},\n",
       " {'target': 1.2537370982337765,\n",
       "  'params': {'colsample_bytree': 0.8890783754749252,\n",
       "   'max_bin': 436.30595264094137,\n",
       "   'max_depth': 15.828946737862111,\n",
       "   'min_child_samples': 161.8401272011775,\n",
       "   'min_child_weight': 23.61248875039366,\n",
       "   'num_leaves': 55.22116705145822,\n",
       "   'reg_alpha': 5.922538549187972,\n",
       "   'reg_lambda': 6.3995702922539115,\n",
       "   'subsample': 0.5716766437045232}},\n",
       " {'target': 1.2526450634067101,\n",
       "  'params': {'colsample_bytree': 0.972334458524792,\n",
       "   'max_bin': 265.70567765753515,\n",
       "   'max_depth': 11.317295519924189,\n",
       "   'min_child_samples': 60.265566299879126,\n",
       "   'min_child_weight': 38.93745078227661,\n",
       "   'num_leaves': 42.24601328866194,\n",
       "   'reg_alpha': 28.426013103943742,\n",
       "   'reg_lambda': 0.18887921456311507,\n",
       "   'subsample': 0.8088177485379385}},\n",
       " {'target': 1.251539019715117,\n",
       "  'params': {'colsample_bytree': 0.8060478613612108,\n",
       "   'max_bin': 312.2976584686309,\n",
       "   'max_depth': 15.549984628116993,\n",
       "   'min_child_samples': 139.54585682966186,\n",
       "   'min_child_weight': 18.615887128115514,\n",
       "   'num_leaves': 41.481278151973655,\n",
       "   'reg_alpha': 34.88458348440397,\n",
       "   'reg_lambda': 0.6031944908210691,\n",
       "   'subsample': 0.8333833577228338}},\n",
       " {'target': 1.2515545762500302,\n",
       "  'params': {'colsample_bytree': 0.640481830861817,\n",
       "   'max_bin': 435.0379450370509,\n",
       "   'max_depth': 13.997795806557395,\n",
       "   'min_child_samples': 169.30259380663517,\n",
       "   'min_child_weight': 26.924368410534857,\n",
       "   'num_leaves': 57.69153705029583,\n",
       "   'reg_alpha': 5.7675960060342195,\n",
       "   'reg_lambda': 9.196441703351635,\n",
       "   'subsample': 0.6129607288812317}},\n",
       " {'target': 1.2514505369806355,\n",
       "  'params': {'colsample_bytree': 0.632308858883009,\n",
       "   'max_bin': 429.3038023004355,\n",
       "   'max_depth': 12.360439684736505,\n",
       "   'min_child_samples': 45.038359281726805,\n",
       "   'min_child_weight': 4.494320290588862,\n",
       "   'num_leaves': 57.659992082810014,\n",
       "   'reg_alpha': 42.36296772346168,\n",
       "   'reg_lambda': 0.592006951039593,\n",
       "   'subsample': 0.8029198591955162}},\n",
       " {'target': 1.2515572769761272,\n",
       "  'params': {'colsample_bytree': 0.7426684621307096,\n",
       "   'max_bin': 319.47038053091336,\n",
       "   'max_depth': 11.14393076819297,\n",
       "   'min_child_samples': 111.7819780035777,\n",
       "   'min_child_weight': 35.34830372241815,\n",
       "   'num_leaves': 35.002158498096705,\n",
       "   'reg_alpha': 36.70612478377702,\n",
       "   'reg_lambda': 3.60187924021144,\n",
       "   'subsample': 0.943125623844969}},\n",
       " {'target': 1.2508394162461933,\n",
       "  'params': {'colsample_bytree': 0.6409494665897852,\n",
       "   'max_bin': 182.82880103784214,\n",
       "   'max_depth': 11.528287278347259,\n",
       "   'min_child_samples': 43.94473877151567,\n",
       "   'min_child_weight': 33.35216978161915,\n",
       "   'num_leaves': 40.72085338877625,\n",
       "   'reg_alpha': 29.156346554624875,\n",
       "   'reg_lambda': 6.572014372431065,\n",
       "   'subsample': 0.780924406810942}},\n",
       " {'target': 1.2527097968044187,\n",
       "  'params': {'colsample_bytree': 0.9628104240486914,\n",
       "   'max_bin': 392.6019667250456,\n",
       "   'max_depth': 12.604657163584061,\n",
       "   'min_child_samples': 137.6165644302899,\n",
       "   'min_child_weight': 6.162790931111218,\n",
       "   'num_leaves': 39.68843400819445,\n",
       "   'reg_alpha': 44.62466896970673,\n",
       "   'reg_lambda': 7.96798253176992,\n",
       "   'subsample': 0.7125838578618998}},\n",
       " {'target': 1.2520945234432344,\n",
       "  'params': {'colsample_bytree': 0.8031537441267949,\n",
       "   'max_bin': 289.92296623985186,\n",
       "   'max_depth': 14.480654564477074,\n",
       "   'min_child_samples': 135.1967905535792,\n",
       "   'min_child_weight': 29.536179613453207,\n",
       "   'num_leaves': 49.69191101606991,\n",
       "   'reg_alpha': 9.131879237349736,\n",
       "   'reg_lambda': 6.842268153732579,\n",
       "   'subsample': 0.9468287787285936}},\n",
       " {'target': 1.2528328393216073,\n",
       "  'params': {'colsample_bytree': 0.9302162160759317,\n",
       "   'max_bin': 239.29488081044582,\n",
       "   'max_depth': 10.730342582905898,\n",
       "   'min_child_samples': 141.7998665207718,\n",
       "   'min_child_weight': 4.039322121950509,\n",
       "   'num_leaves': 56.16605816202684,\n",
       "   'reg_alpha': 23.405828602465323,\n",
       "   'reg_lambda': 8.838878538427577,\n",
       "   'subsample': 0.9090863877714945}},\n",
       " {'target': 1.2519671546389504,\n",
       "  'params': {'colsample_bytree': 0.8226559961213534,\n",
       "   'max_bin': 418.8178956430658,\n",
       "   'max_depth': 9.865169179254032,\n",
       "   'min_child_samples': 51.89988947054562,\n",
       "   'min_child_weight': 10.053642747626913,\n",
       "   'num_leaves': 55.874070044144354,\n",
       "   'reg_alpha': 15.548395899893334,\n",
       "   'reg_lambda': 8.402663194291186,\n",
       "   'subsample': 0.9561864958093883}},\n",
       " {'target': 1.253959469706834,\n",
       "  'params': {'colsample_bytree': 0.9781113328361428,\n",
       "   'max_bin': 232.84687600366271,\n",
       "   'max_depth': 11.499673377388664,\n",
       "   'min_child_samples': 170.363564772274,\n",
       "   'min_child_weight': 30.437054963704664,\n",
       "   'num_leaves': 45.23442469480794,\n",
       "   'reg_alpha': 8.400568023435246,\n",
       "   'reg_lambda': 0.9375129684839731,\n",
       "   'subsample': 0.8084553190676591}},\n",
       " {'target': 1.2525457708379533,\n",
       "  'params': {'colsample_bytree': 0.9303434996072725,\n",
       "   'max_bin': 325.13104736053697,\n",
       "   'max_depth': 15.93151047882213,\n",
       "   'min_child_samples': 120.17905412333756,\n",
       "   'min_child_weight': 1.1001671428372037,\n",
       "   'num_leaves': 29.00095276907647,\n",
       "   'reg_alpha': 25.80923156197473,\n",
       "   'reg_lambda': 5.160869697422219,\n",
       "   'subsample': 0.5703560414423314}},\n",
       " {'target': 1.2510676893709294,\n",
       "  'params': {'colsample_bytree': 0.7405498719224073,\n",
       "   'max_bin': 120.09126734365545,\n",
       "   'max_depth': 12.941725031356032,\n",
       "   'min_child_samples': 53.75607426089902,\n",
       "   'min_child_weight': 42.67674438905004,\n",
       "   'num_leaves': 47.65645884299404,\n",
       "   'reg_alpha': 10.657030784872696,\n",
       "   'reg_lambda': 1.9862443324975898,\n",
       "   'subsample': 0.8183674135844643}},\n",
       " {'target': 1.250315865641987,\n",
       "  'params': {'colsample_bytree': 0.5285839690801153,\n",
       "   'max_bin': 456.3688492632358,\n",
       "   'max_depth': 13.973563539578148,\n",
       "   'min_child_samples': 96.71934046157652,\n",
       "   'min_child_weight': 41.56458449914903,\n",
       "   'num_leaves': 61.51356737319794,\n",
       "   'reg_alpha': 29.916479237807728,\n",
       "   'reg_lambda': 3.569830892060643,\n",
       "   'subsample': 0.8466234848633365}},\n",
       " {'target': 1.251966081274364,\n",
       "  'params': {'colsample_bytree': 0.8262675434634367,\n",
       "   'max_bin': 179.02643444189138,\n",
       "   'max_depth': 12.190589647409947,\n",
       "   'min_child_samples': 25.42405323323092,\n",
       "   'min_child_weight': 22.467031735522987,\n",
       "   'num_leaves': 41.435847707404264,\n",
       "   'reg_alpha': 25.052983850217746,\n",
       "   'reg_lambda': 2.005137409610909,\n",
       "   'subsample': 0.6374816635227165}},\n",
       " {'target': 1.2521979538448818,\n",
       "  'params': {'colsample_bytree': 0.9644030062523238,\n",
       "   'max_bin': 330.0928781095815,\n",
       "   'max_depth': 11.73763609663307,\n",
       "   'min_child_samples': 22.200684457930734,\n",
       "   'min_child_weight': 30.449321845606374,\n",
       "   'num_leaves': 42.41391927150943,\n",
       "   'reg_alpha': 41.1241425119106,\n",
       "   'reg_lambda': 7.101780863951866,\n",
       "   'subsample': 0.7549971229139905}},\n",
       " {'target': 1.2514699948335697,\n",
       "  'params': {'colsample_bytree': 0.6988204802600908,\n",
       "   'max_bin': 466.75424161263555,\n",
       "   'max_depth': 8.178977830636157,\n",
       "   'min_child_samples': 141.31468721621735,\n",
       "   'min_child_weight': 6.810699765361502,\n",
       "   'num_leaves': 46.30444012544474,\n",
       "   'reg_alpha': 34.40986192906314,\n",
       "   'reg_lambda': 0.21031728177246328,\n",
       "   'subsample': 0.8805600329766623}},\n",
       " {'target': 1.2510131394284554,\n",
       "  'params': {'colsample_bytree': 0.6587283396471605,\n",
       "   'max_bin': 250.5286386374607,\n",
       "   'max_depth': 11.189562282462193,\n",
       "   'min_child_samples': 100.81813684545703,\n",
       "   'min_child_weight': 48.75445679344283,\n",
       "   'num_leaves': 36.577758318770336,\n",
       "   'reg_alpha': 41.14778812699356,\n",
       "   'reg_lambda': 9.618286668999609,\n",
       "   'subsample': 0.6229366817412965}},\n",
       " {'target': 1.2525896341228486,\n",
       "  'params': {'colsample_bytree': 0.9982660890256111,\n",
       "   'max_bin': 254.03913543906165,\n",
       "   'max_depth': 15.72064662080102,\n",
       "   'min_child_samples': 172.25633471197003,\n",
       "   'min_child_weight': 4.749826121182029,\n",
       "   'num_leaves': 35.99850836024811,\n",
       "   'reg_alpha': 34.224816343148206,\n",
       "   'reg_lambda': 8.12950340865832,\n",
       "   'subsample': 0.8197334217464274}},\n",
       " {'target': 1.252474625990353,\n",
       "  'params': {'colsample_bytree': 0.9707101482347569,\n",
       "   'max_bin': 151.73780030563316,\n",
       "   'max_depth': 13.90288866933377,\n",
       "   'min_child_samples': 46.182587729009526,\n",
       "   'min_child_weight': 37.888812663146865,\n",
       "   'num_leaves': 38.30708609406997,\n",
       "   'reg_alpha': 47.89761393961768,\n",
       "   'reg_lambda': 5.180723493699807,\n",
       "   'subsample': 0.5226788318286884}},\n",
       " {'target': 1.2516714146870185,\n",
       "  'params': {'colsample_bytree': 0.8323626633911705,\n",
       "   'max_bin': 52.630796011433475,\n",
       "   'max_depth': 14.834088173954108,\n",
       "   'min_child_samples': 100.82697953897299,\n",
       "   'min_child_weight': 22.84390430193939,\n",
       "   'num_leaves': 59.277532034313865,\n",
       "   'reg_alpha': 25.29624148656783,\n",
       "   'reg_lambda': 7.740368689783408,\n",
       "   'subsample': 0.9655823792101785}},\n",
       " {'target': 1.2513901962123721,\n",
       "  'params': {'colsample_bytree': 0.7944926166116978,\n",
       "   'max_bin': 227.69929252784215,\n",
       "   'max_depth': 11.987117401638862,\n",
       "   'min_child_samples': 10.967357099553864,\n",
       "   'min_child_weight': 29.732788400470994,\n",
       "   'num_leaves': 58.59338148377599,\n",
       "   'reg_alpha': 36.537587754798636,\n",
       "   'reg_lambda': 5.997013317901609,\n",
       "   'subsample': 0.6190174283535954}},\n",
       " {'target': 1.2502695116165727,\n",
       "  'params': {'colsample_bytree': 0.5220894724290079,\n",
       "   'max_bin': 85.94837484270441,\n",
       "   'max_depth': 13.637802636589656,\n",
       "   'min_child_samples': 31.69873590274043,\n",
       "   'min_child_weight': 25.53921945576096,\n",
       "   'num_leaves': 55.779419530470044,\n",
       "   'reg_alpha': 13.89522161333654,\n",
       "   'reg_lambda': 1.522069194132511,\n",
       "   'subsample': 0.9647340498702532}},\n",
       " {'target': 1.2517675926801293,\n",
       "  'params': {'colsample_bytree': 0.8718504061169674,\n",
       "   'max_bin': 449.53174452689933,\n",
       "   'max_depth': 9.927354053089399,\n",
       "   'min_child_samples': 64.2033796743264,\n",
       "   'min_child_weight': 32.30787507504271,\n",
       "   'num_leaves': 42.561999452152484,\n",
       "   'reg_alpha': 49.446888350416486,\n",
       "   'reg_lambda': 7.1644239765664395,\n",
       "   'subsample': 0.8816395684783181}},\n",
       " {'target': 1.2526101568809276,\n",
       "  'params': {'colsample_bytree': 0.9589527057920451,\n",
       "   'max_bin': 242.46898207795797,\n",
       "   'max_depth': 9.055342212793665,\n",
       "   'min_child_samples': 161.4658862490677,\n",
       "   'min_child_weight': 26.262216527060716,\n",
       "   'num_leaves': 47.08564067766474,\n",
       "   'reg_alpha': 28.483963334243608,\n",
       "   'reg_lambda': 1.2676425560544602,\n",
       "   'subsample': 0.7036095679103438}},\n",
       " {'target': 1.2507038020187256,\n",
       "  'params': {'colsample_bytree': 0.5288123810873695,\n",
       "   'max_bin': 298.3632940551493,\n",
       "   'max_depth': 14.46819764959875,\n",
       "   'min_child_samples': 182.4305882973765,\n",
       "   'min_child_weight': 37.647486427741015,\n",
       "   'num_leaves': 54.35658240763554,\n",
       "   'reg_alpha': 7.912768101857651,\n",
       "   'reg_lambda': 3.0095185838236933,\n",
       "   'subsample': 0.773150758899048}},\n",
       " {'target': 1.2531644776798476,\n",
       "  'params': {'colsample_bytree': 0.7962009281372404,\n",
       "   'max_bin': 309.4087367197383,\n",
       "   'max_depth': 8.871527099324688,\n",
       "   'min_child_samples': 194.40921565317748,\n",
       "   'min_child_weight': 35.82659426060641,\n",
       "   'num_leaves': 40.28172250700207,\n",
       "   'reg_alpha': 5.876030282846928,\n",
       "   'reg_lambda': 1.2072004066381457,\n",
       "   'subsample': 0.6584537657874912}}]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbBO.res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.251146063157274, 1.2536079279558263, 1.2537370982337765, 1.2526450634067101, 1.251539019715117, 1.2515545762500302, 1.2514505369806355, 1.2515572769761272, 1.2508394162461933, 1.2527097968044187, 1.2520945234432344, 1.2528328393216073, 1.2519671546389504, 1.253959469706834, 1.2525457708379533, 1.2510676893709294, 1.250315865641987, 1.251966081274364, 1.2521979538448818, 1.2514699948335697, 1.2510131394284554, 1.2525896341228486, 1.252474625990353, 1.2516714146870185, 1.2513901962123721, 1.2502695116165727, 1.2517675926801293, 1.2526101568809276, 1.2507038020187256, 1.2531644776798476]\n",
      "minimum target index: 25\n"
     ]
    }
   ],
   "source": [
    "# dictionary에 있는 target값을 모두 추출\n",
    "target_list = []\n",
    "for result in lgbBO.res:\n",
    "    target = result['target']\n",
    "    target_list.append(target)\n",
    "print(target_list)\n",
    "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
    "print('minimum target index:', np.argmin(np.array(target_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 1.2502695116165727, 'params': {'colsample_bytree': 0.5220894724290079, 'max_bin': 85.94837484270441, 'max_depth': 13.637802636589656, 'min_child_samples': 31.69873590274043, 'min_child_weight': 25.53921945576096, 'num_leaves': 55.779419530470044, 'reg_alpha': 13.89522161333654, 'reg_lambda': 1.522069194132511, 'subsample': 0.9647340498702532}}\n"
     ]
    }
   ],
   "source": [
    "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출. \n",
    "min_dict = lgbBO.res[np.argmin(np.array(target_list))]\n",
    "print(min_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftr = X_train_select\n",
    "target=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst=pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_apps_all_with_oof(ftr, target, nfolds=5):\n",
    "\n",
    "    # nfolds 개의 cross validatin fold set을 가지는 KFold 생성 \n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=0)\n",
    "    \n",
    "    # Out of Folds로 학습된 모델의 validation set을 예측하여 결과 확률을 담을 array 생성.\n",
    "    # validation set가 n_split갯수만큼 있으므로 크기는 ftr_app의 크기가 되어야 함. \n",
    "    oof_preds = np.zeros(ftr.shape[0])\n",
    "    \n",
    "    # Ouf of Folds로 학습된 모델의 test dataset을 예측하여 결과 확률을 담을 array 생성. \n",
    "    test_preds = np.zeros((X_tst.shape[0], 6))\n",
    "    \n",
    "    # n_estimators를 4000까지 확대. \n",
    "    clf = LGBMClassifier(\n",
    "                n_jobs=4,\n",
    "                n_estimators=4000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=14,\n",
    "                num_leaves=56,\n",
    "                colsample_bytree=0.5221,\n",
    "                subsample=0.9647,\n",
    "                max_bin=86,\n",
    "                reg_alpha=13.8952,\n",
    "                reg_lambda=1.5220,\n",
    "                min_child_weight=25.5392,\n",
    "                min_child_samples=32,\n",
    "                silent=-1,\n",
    "                verbose=-1,\n",
    "                )\n",
    "    \n",
    "    # nfolds 번 cross validation Iteration 반복하면서 OOF 방식으로 학습 및 테스트 데이터 예측\n",
    "    for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(ftr)):\n",
    "        print('##### iteration', fold_idx, '시작')\n",
    "        # 학습용 데이터 세트의 인덱스와 검증용 데이터 세트의 인덱스 추출하여 이를 기반으로 학습/검증 데이터 추출\n",
    "        train_x = ftr.iloc[train_idx,:]\n",
    "        train_y = target.iloc[train_idx]\n",
    "        valid_x = ftr.iloc[valid_idx,:]\n",
    "        valid_y = target.iloc[valid_idx]\n",
    "        \n",
    "        # 추출된 학습/검증 데이터 세트로 모델 학습. early_stopping은 200으로 증가. \n",
    "        clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'logloss', verbose= 200, \n",
    "                early_stopping_rounds= 200)\n",
    "        \n",
    "        # 검증 데이터 세트로 예측된 확률 저장. 사용되지는 않음. \n",
    "        #oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]    \n",
    "        \n",
    "        # 학습된 모델로 테스트 데이터 세트에 예측 확률 계산.\n",
    "        # nfolds 번 반복 실행하므로 평균 확률을 구하기 위해 개별 수행시 마다 수행 횟수로 나눈 확률을 추후에 더해서 최종 평균 확률 계산. \n",
    "        test_preds += clf.predict_proba(X_test_select, num_iteration=clf.best_iteration_)/folds.n_splits\n",
    "             \n",
    "    return clf, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### iteration 0 시작\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's multi_logloss: 1.23506\tvalid_1's multi_logloss: 1.27517\n",
      "[400]\ttraining's multi_logloss: 1.18753\tvalid_1's multi_logloss: 1.25902\n",
      "[600]\ttraining's multi_logloss: 1.15117\tvalid_1's multi_logloss: 1.25344\n",
      "[800]\ttraining's multi_logloss: 1.11934\tvalid_1's multi_logloss: 1.25078\n",
      "[1000]\ttraining's multi_logloss: 1.09058\tvalid_1's multi_logloss: 1.24953\n",
      "[1200]\ttraining's multi_logloss: 1.06415\tvalid_1's multi_logloss: 1.24904\n",
      "[1400]\ttraining's multi_logloss: 1.03942\tvalid_1's multi_logloss: 1.24878\n",
      "[1600]\ttraining's multi_logloss: 1.01622\tvalid_1's multi_logloss: 1.24897\n",
      "Early stopping, best iteration is:\n",
      "[1453]\ttraining's multi_logloss: 1.03314\tvalid_1's multi_logloss: 1.24876\n",
      "##### iteration 1 시작\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's multi_logloss: 1.23631\tvalid_1's multi_logloss: 1.27079\n",
      "[400]\ttraining's multi_logloss: 1.18871\tvalid_1's multi_logloss: 1.25483\n",
      "[600]\ttraining's multi_logloss: 1.15234\tvalid_1's multi_logloss: 1.24905\n",
      "[800]\ttraining's multi_logloss: 1.12049\tvalid_1's multi_logloss: 1.24624\n",
      "[1000]\ttraining's multi_logloss: 1.09176\tvalid_1's multi_logloss: 1.24473\n",
      "[1200]\ttraining's multi_logloss: 1.06527\tvalid_1's multi_logloss: 1.24412\n",
      "[1400]\ttraining's multi_logloss: 1.04052\tvalid_1's multi_logloss: 1.24392\n",
      "Early stopping, best iteration is:\n",
      "[1389]\ttraining's multi_logloss: 1.04185\tvalid_1's multi_logloss: 1.2439\n",
      "##### iteration 2 시작\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's multi_logloss: 1.23794\tvalid_1's multi_logloss: 1.26246\n",
      "[400]\ttraining's multi_logloss: 1.19031\tvalid_1's multi_logloss: 1.24758\n",
      "[600]\ttraining's multi_logloss: 1.15387\tvalid_1's multi_logloss: 1.24213\n",
      "[800]\ttraining's multi_logloss: 1.12194\tvalid_1's multi_logloss: 1.23949\n",
      "[1000]\ttraining's multi_logloss: 1.09314\tvalid_1's multi_logloss: 1.238\n",
      "[1200]\ttraining's multi_logloss: 1.06657\tvalid_1's multi_logloss: 1.23733\n",
      "[1400]\ttraining's multi_logloss: 1.04173\tvalid_1's multi_logloss: 1.23709\n",
      "[1600]\ttraining's multi_logloss: 1.01822\tvalid_1's multi_logloss: 1.23717\n",
      "Early stopping, best iteration is:\n",
      "[1411]\ttraining's multi_logloss: 1.04042\tvalid_1's multi_logloss: 1.23709\n",
      "##### iteration 3 시작\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's multi_logloss: 1.23547\tvalid_1's multi_logloss: 1.27248\n",
      "[400]\ttraining's multi_logloss: 1.18777\tvalid_1's multi_logloss: 1.25801\n",
      "[600]\ttraining's multi_logloss: 1.15126\tvalid_1's multi_logloss: 1.25316\n",
      "[800]\ttraining's multi_logloss: 1.11943\tvalid_1's multi_logloss: 1.25091\n",
      "[1000]\ttraining's multi_logloss: 1.09071\tvalid_1's multi_logloss: 1.24956\n",
      "[1200]\ttraining's multi_logloss: 1.06425\tvalid_1's multi_logloss: 1.24905\n",
      "[1400]\ttraining's multi_logloss: 1.03954\tvalid_1's multi_logloss: 1.24898\n",
      "Early stopping, best iteration is:\n",
      "[1365]\ttraining's multi_logloss: 1.04374\tvalid_1's multi_logloss: 1.2489\n",
      "##### iteration 4 시작\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's multi_logloss: 1.23458\tvalid_1's multi_logloss: 1.27731\n",
      "[400]\ttraining's multi_logloss: 1.18677\tvalid_1's multi_logloss: 1.26209\n",
      "[600]\ttraining's multi_logloss: 1.15036\tvalid_1's multi_logloss: 1.25649\n",
      "[800]\ttraining's multi_logloss: 1.1184\tvalid_1's multi_logloss: 1.25368\n",
      "[1000]\ttraining's multi_logloss: 1.08962\tvalid_1's multi_logloss: 1.25239\n",
      "[1200]\ttraining's multi_logloss: 1.06314\tvalid_1's multi_logloss: 1.25185\n",
      "[1400]\ttraining's multi_logloss: 1.03828\tvalid_1's multi_logloss: 1.25176\n",
      "Early stopping, best iteration is:\n",
      "[1306]\ttraining's multi_logloss: 1.04981\tvalid_1's multi_logloss: 1.25173\n"
     ]
    }
   ],
   "source": [
    "clf, test_preds = train_apps_all_with_oof(ftr, target, nfolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################코드 돌아가면 소리 나는거################### \n",
    "import winsound as sd\n",
    "def beepsound():\n",
    "    fr = 2000    # range : 37 ~ 32767\n",
    "    du = 1000     # 1000 ms = =1second\n",
    "    sd.Beep(fr, du) # winsound.Beep(frequency, duration)\n",
    "beepsound()\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_tst[X_tst.columns[1:]] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst.set_index('CLNT_ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst.to_csv('11_23_w2v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
