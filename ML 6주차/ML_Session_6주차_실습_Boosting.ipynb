{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "pd.set_option('max_columns', 30, 'max_rows', 20)\n",
    "\n",
    "\n",
    "# Data Split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed = 42\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "\n",
    "\n",
    "# Data Preprocess\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Modeling\n",
    "#  - Bagging,models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#  - Boosting models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/temp_train.csv')\n",
    "test = pd.read_csv('./data/temp_test.csv')\n",
    "target = pd.read_csv('./data/y_train.csv').LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 20) (113104, 20) (150000,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(random_state=seed)\n",
    "extra_clf = ExtraTreesClassifier(random_state=seed)\n",
    "gbm_clf = GradientBoostingClassifier(random_state=seed) # gbm이 오래 걸림\n",
    "xgb_clf = XGBClassifier(random_state=seed, n_jobs=-1)\n",
    "lgb_clf = LGBMClassifier(random_state=seed, n_jobs=-1)\n",
    "\n",
    "models = [rf_clf, extra_clf, gbm_clf, xgb_clf, lgb_clf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 평균 성능: 2.6038\n",
      "ExtraTreesClassifier 평균 성능: 4.0941\n",
      "GradientBoostingClassifier 평균 성능: 1.3566\n",
      "XGBClassifier 평균 성능: 1.3653\n",
      "LGBMClassifier 평균 성능: 1.3562\n"
     ]
    }
   ],
   "source": [
    "# Check models' bacis score\n",
    "\n",
    "for model in models:\n",
    "    loglosses = cross_val_score(model, train.values, target, scoring='neg_log_loss', cv=skf, n_jobs=-1)\n",
    "    logloss_mean = -np.mean(loglosses)\n",
    "    print(f'{model.__class__.__name__} 평균 성능: {logloss_mean:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB_clf bayesian example\n",
    "\n",
    "pbounds = {'learning_rate' : (0.01,0.1),\n",
    "           'n_estimators' : (100,300),\n",
    "           'max_depth' : (10,30),\n",
    "           'subsample' : (0.8,1),\n",
    "           'colsample_bytree' : (0.75,1.0),\n",
    "           'min_child_samples' : (20, 30), \n",
    "           'num_leaves': (20, 35)\n",
    "           }\n",
    "\n",
    "def lgb_opt(learning_rate, n_estimators, max_depth, subsample, colsample_bytree, min_child_samples, num_leaves):\n",
    "    \n",
    "    params = {\n",
    "        'learning_rate' : learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'subsample' : subsample,\n",
    "        'colsample_bytree' : colsample_bytree,\n",
    "        'min_child_samples' : int(round(min_child_samples)),\n",
    "        'num_leaves' : int(round(num_leaves)),\n",
    "        'objective' : 'binary',\n",
    "        'random_state' : seed,\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "\n",
    "    lgb_reg = LGBMClassifier(**params)\n",
    "    \n",
    "    scores = cross_val_score(lgb_reg, train.values, target,scoring = 'neg_log_loss', cv=skf, n_jobs=-1)\n",
    "    mean_score = np.mean(scores)\n",
    "    \n",
    "    return mean_score\n",
    "\n",
    "\n",
    "BO_lgb = BayesianOptimization(f = lgb_opt, pbounds = pbounds, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-1.356   \u001b[0m | \u001b[0m 0.8436  \u001b[0m | \u001b[0m 0.09556 \u001b[0m | \u001b[0m 24.64   \u001b[0m | \u001b[0m 25.99   \u001b[0m | \u001b[0m 131.2   \u001b[0m | \u001b[0m 22.34   \u001b[0m | \u001b[0m 0.8116  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-1.358   \u001b[0m | \u001b[0m 0.9665  \u001b[0m | \u001b[0m 0.0641  \u001b[0m | \u001b[0m 24.16   \u001b[0m | \u001b[0m 20.21   \u001b[0m | \u001b[0m 294.0   \u001b[0m | \u001b[0m 32.49   \u001b[0m | \u001b[0m 0.8425  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m-1.355   \u001b[0m | \u001b[95m 0.7955  \u001b[0m | \u001b[95m 0.02651 \u001b[0m | \u001b[95m 16.08   \u001b[0m | \u001b[95m 25.25   \u001b[0m | \u001b[95m 186.4   \u001b[0m | \u001b[95m 24.37   \u001b[0m | \u001b[95m 0.9224  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m-1.355   \u001b[0m | \u001b[95m 0.7849  \u001b[0m | \u001b[95m 0.03629 \u001b[0m | \u001b[95m 17.33   \u001b[0m | \u001b[95m 24.56   \u001b[0m | \u001b[95m 257.0   \u001b[0m | \u001b[95m 23.0    \u001b[0m | \u001b[95m 0.9028  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-1.362   \u001b[0m | \u001b[0m 0.8981  \u001b[0m | \u001b[0m 0.01418 \u001b[0m | \u001b[0m 22.15   \u001b[0m | \u001b[0m 21.71   \u001b[0m | \u001b[0m 113.0   \u001b[0m | \u001b[0m 34.23   \u001b[0m | \u001b[0m 0.9931  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-1.356   \u001b[0m | \u001b[0m 0.7851  \u001b[0m | \u001b[0m 0.08104 \u001b[0m | \u001b[0m 14.58   \u001b[0m | \u001b[0m 25.69   \u001b[0m | \u001b[0m 185.6   \u001b[0m | \u001b[0m 24.55   \u001b[0m | \u001b[0m 0.9574  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-1.356   \u001b[0m | \u001b[0m 0.7913  \u001b[0m | \u001b[0m 0.07408 \u001b[0m | \u001b[0m 23.19   \u001b[0m | \u001b[0m 21.35   \u001b[0m | \u001b[0m 189.0   \u001b[0m | \u001b[0m 24.44   \u001b[0m | \u001b[0m 0.8674  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-1.355   \u001b[0m | \u001b[0m 0.9276  \u001b[0m | \u001b[0m 0.05097 \u001b[0m | \u001b[0m 19.22   \u001b[0m | \u001b[0m 28.49   \u001b[0m | \u001b[0m 194.8   \u001b[0m | \u001b[0m 22.27   \u001b[0m | \u001b[0m 0.8715  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-1.36    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 21.94   \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 190.7   \u001b[0m | \u001b[0m 32.28   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-1.355   \u001b[0m | \u001b[0m 0.9547  \u001b[0m | \u001b[0m 0.05075 \u001b[0m | \u001b[0m 17.56   \u001b[0m | \u001b[0m 21.17   \u001b[0m | \u001b[0m 191.4   \u001b[0m | \u001b[0m 20.56   \u001b[0m | \u001b[0m 0.8339  \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_lgb.maximize(init_points=5, n_iter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7848734651630105,\n",
       " 'learning_rate': 0.03629301836816964,\n",
       " 'max_depth': 17,\n",
       " 'min_child_samples': 25,\n",
       " 'n_estimators': 257,\n",
       " 'num_leaves': 23,\n",
       " 'subsample': 0.9028468876827224,\n",
       " 'objective': 'binary',\n",
       " 'n_jobs': -1,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_lgb.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['objective'] = 'binary'\n",
    "max_params['n_jobs'] = -1\n",
    "max_params['random_state'] = seed\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM 모델의 튜닝 평균 성능:  1.3550\n"
     ]
    }
   ],
   "source": [
    "# 해당 코드는 cross_val_score를 풀어 쓴 것임\n",
    "# cross_val_score와의 차이점:\n",
    "# - cross_val_score는 한 줄로 간단명료하게 cross_validation을 할 수 있는 패키지로 모델이 fit이 되지 않음\n",
    "                        #   해당 패키지는 모델의 기본적 평균적인 성능을 빠르게 체크하여 볼 수 있음\n",
    "# - cross_val_score를 아래와 같이 풀어써서 모델을 fit 시킬 수 있음\n",
    "\n",
    "lgb_clf = LGBMClassifier(**max_params)\n",
    "\n",
    "scores = []\n",
    "for iter_count, (train_idx, valid_idx) in enumerate(skf.split(train, target)):\n",
    "    \n",
    "    X_train, X_valid = train.values[train_idx], train.values[valid_idx]\n",
    "    y_train, y_valid = target.values[train_idx], target.values[valid_idx]\n",
    "    \n",
    "    lgb_clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = lgb_clf.predict_proba(X_valid)\n",
    "    score = log_loss(y_valid, pred)\n",
    "    scores.append(score)\n",
    "print(f'LGBM 모델의 튜닝 평균 성능:  {np.mean(scores):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>F20</th>\n",
       "      <th>F30</th>\n",
       "      <th>F40</th>\n",
       "      <th>M20</th>\n",
       "      <th>M30</th>\n",
       "      <th>M40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.109960</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>0.347190</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.055943</td>\n",
       "      <td>0.062377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.327016</td>\n",
       "      <td>0.334074</td>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.090947</td>\n",
       "      <td>0.077261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.073110</td>\n",
       "      <td>0.344245</td>\n",
       "      <td>0.402682</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.068432</td>\n",
       "      <td>0.098409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.021482</td>\n",
       "      <td>0.447789</td>\n",
       "      <td>0.462944</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.017197</td>\n",
       "      <td>0.049295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.463715</td>\n",
       "      <td>0.317726</td>\n",
       "      <td>0.181747</td>\n",
       "      <td>0.009244</td>\n",
       "      <td>0.011122</td>\n",
       "      <td>0.016446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113099</th>\n",
       "      <td>113099</td>\n",
       "      <td>0.213674</td>\n",
       "      <td>0.461255</td>\n",
       "      <td>0.276609</td>\n",
       "      <td>0.009629</td>\n",
       "      <td>0.017996</td>\n",
       "      <td>0.020837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113100</th>\n",
       "      <td>113100</td>\n",
       "      <td>0.126198</td>\n",
       "      <td>0.462531</td>\n",
       "      <td>0.348812</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.027846</td>\n",
       "      <td>0.027170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113101</th>\n",
       "      <td>113101</td>\n",
       "      <td>0.145075</td>\n",
       "      <td>0.340562</td>\n",
       "      <td>0.336845</td>\n",
       "      <td>0.030168</td>\n",
       "      <td>0.069697</td>\n",
       "      <td>0.077654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113102</th>\n",
       "      <td>113102</td>\n",
       "      <td>0.095116</td>\n",
       "      <td>0.465259</td>\n",
       "      <td>0.324009</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.051622</td>\n",
       "      <td>0.048774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113103</th>\n",
       "      <td>113103</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.304019</td>\n",
       "      <td>0.388966</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>0.073657</td>\n",
       "      <td>0.130134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113104 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       F20       F30       F40       M20       M30       M40\n",
       "0            0  0.109960  0.404298  0.347190  0.020232  0.055943  0.062377\n",
       "1            1  0.143275  0.327016  0.334074  0.027427  0.090947  0.077261\n",
       "2            2  0.073110  0.344245  0.402682  0.013123  0.068432  0.098409\n",
       "3            3  0.021482  0.447789  0.462944  0.001293  0.017197  0.049295\n",
       "4            4  0.463715  0.317726  0.181747  0.009244  0.011122  0.016446\n",
       "...        ...       ...       ...       ...       ...       ...       ...\n",
       "113099  113099  0.213674  0.461255  0.276609  0.009629  0.017996  0.020837\n",
       "113100  113100  0.126198  0.462531  0.348812  0.007444  0.027846  0.027170\n",
       "113101  113101  0.145075  0.340562  0.336845  0.030168  0.069697  0.077654\n",
       "113102  113102  0.095116  0.465259  0.324009  0.015219  0.051622  0.048774\n",
       "113103  113103  0.087900  0.304019  0.388966  0.015324  0.073657  0.130134\n",
       "\n",
       "[113104 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_pred = lgb_clf.predict_proba(test)\n",
    "\n",
    "columns = ['F20','F30','F40','M20','M30','M40']\n",
    "index_df = pd.DataFrame(test.index)\n",
    "sub = pd.DataFrame(sub_pred, columns=columns)\n",
    "\n",
    "submission = pd.concat([index_df, sub], axis=1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **────────────────────────End of Pipeline──────────────────────**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
